# app.py
from __future__ import annotations
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, Any, List, Optional, Tuple
import os, time, re

# ===== external modules (‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°) =====
from task import (
    process_input as task_process_input,
    classify_path as task_classify_path,  # classifier ‡∏™‡∏≥‡∏£‡∏≠‡∏á
)
from autofill_core import run_autofill
from search_llm import ask_with_cli_and_fallback
from search_core import search_google
from scrape_core import scrape_text
from llm_core import ask_llm_raw
from dotenv import load_dotenv
load_dotenv()

app = FastAPI(title="Unified Orchestrator (feature-lock + interactive fill_form)")

# ===== CORS =====
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== Global STATE =====
STATE: Dict[str, Any] = {
    "logs": [],
    "feature_lock": None,              # "task" | "search" | "plan" | "fill_form" | None
    "fill_form_session": None,         # {"form": dict, "missing": [...], "filled": [...]}
    "task_session": None,
    "search_session": None,
}

# ===== Models =====
class ChatIn(BaseModel):
    text: str

# ---------- helpers: time/log ----------
def _now() -> float: return time.time()
def add_log(feature: str, role: str, text: str) -> None:
    STATE["logs"].append({"ts": _now(), "feature": feature, "role": role, "text": text})

# ---------- helpers: search context ----------
def build_search_prompt(new_user_text: str, max_pairs: int = 3) -> str:
    hist = [e for e in STATE["logs"] if e["feature"] == "search"]
    pairs: List[str] = []
    u_buf: Optional[str] = None
    for e in hist[-(max_pairs * 2):]:
        if e["role"] == "user":
            u_buf = e["text"]
        elif e["role"] == "assistant" and u_buf is not None:
            pairs.append(f"‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {u_buf}\n‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢(‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤): {e['text']}")
            u_buf = None
    context = "\n\n".join(pairs)
    return f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤:\n{context}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà: {new_user_text}" if context else new_user_text

# ---------- helpers: intents ----------
def intents_from_task_out(out: Dict[str, Any]) -> List[str]:
    items: List[str] = []
    if isinstance(out.get("intent"), list): items.extend(out["intent"])
    di = out.get("decorated_input")
    if isinstance(di, dict):
        decorated = di.get("decorated", [])
        if isinstance(decorated, list):
            for obj in decorated:
                if isinstance(obj, dict) and isinstance(obj.get("intent"), list):
                    items.extend(obj["intent"])
    old = out.get("decorated_inputs")
    if isinstance(old, list):
        for obj in old:
            if isinstance(obj, dict) and isinstance(obj.get("intent"), list):
                items.extend(obj["intent"])
    return [str(x).strip().lower() for x in items]

def _intent_bucket(name: str) -> str:
    n = (name or "").strip().lower()
    if "form" in n: return "fill_form"
    if "googlesearch" in n or "search" in n: return "search"
    if "plan" in n: return "plan"
    if n in ("task","add","check","edit","remove"): return "task"
    return ""

def detect_multi_feature_request(intents: List[str]) -> List[str]:
    buckets: List[str] = []
    for it in intents:
        b = _intent_bucket(it)
        if b and b not in buckets:
            buckets.append(b)
    return buckets

# ---------- helpers: switch / exit ----------
def parse_switch_command(text: str) -> Tuple[str, Optional[str]]:
    t = (text or "").strip().lower()
    if re.search(r"(‡∏≠‡∏≠‡∏Å|‡∏à‡∏ö|‡∏û‡∏≠‡πÅ‡∏•‡πâ‡∏ß|‡∏´‡∏¢‡∏∏‡∏î|‡πÄ‡∏•‡∏¥‡∏Å|end|exit)\b", t):
        return "exit", None
    if re.search(r"(‡πÑ‡∏õ(‡∏ó‡∏µ‡πà)?|‡∏™‡∏•‡∏±‡∏ö|‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô|switch)\s*(‡πÇ‡∏´‡∏°‡∏î)?\s*(search|‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤)", t):
        return "switch", "search"
    if re.search(r"(‡πÑ‡∏õ(‡∏ó‡∏µ‡πà)?|‡∏™‡∏•‡∏±‡∏ö|‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô|switch)\s*(‡πÇ‡∏´‡∏°‡∏î)?\s*(task|‡∏á‡∏≤‡∏ô|‡∏ó‡∏≤‡∏™‡∏Å‡πå)", t):
        return "switch", "task"
    if re.search(r"(‡πÑ‡∏õ(‡∏ó‡∏µ‡πà)?|‡∏™‡∏•‡∏±‡∏ö|‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô|switch)\s*(‡πÇ‡∏´‡∏°‡∏î)?\s*(form|‡∏ü‡∏≠‡∏£‡πå‡∏°|‡∏Å‡∏£‡∏≠‡∏Å‡∏ü‡∏≠‡∏£‡πå‡∏°|fill\s*form)", t):
        return "switch", "fill_form"
    if re.search(r"(‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô|‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)", t):
        return "exit", None
    return "", None

# ---------- helpers: feature label ----------
def feature_badge(feature: str) -> str:
    mapping = {
        "task": "TASK",
        "search": "SEARCH",
        "plan": "PLAN",
        "fill_form": "FILL_FORM",
        "unknown": "UNKNOWN"
    }
    return f"[‡πÇ‡∏´‡∏°‡∏î: {mapping.get(feature, feature).upper()}] "

# ---------- decide feature ----------
def decide_feature(text: str, out: Dict[str, Any]) -> str:
    low = (text or "").strip().lower()

    # ‡πÄ‡∏Ç‡πâ‡∏≤ fill_form ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡∏±‡πà‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    explicit_fill = bool(re.search(r"(‡∏ä‡πà‡∏ß‡∏¢)?\s*(‡∏Å‡∏£‡∏≠‡∏Å|‡πÄ‡∏ï‡∏¥‡∏°)\s*(‡πÅ‡∏ö‡∏ö)?‡∏ü‡∏≠‡∏£‡πå‡∏°", low)) \
        or any(k in low for k in ("‡∏Å‡∏£‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°","‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏≠‡∏Å‡∏ü‡∏≠‡∏£‡πå‡∏°","‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏≠‡∏£‡πå‡∏°","‡πÄ‡∏õ‡∏¥‡∏î‡∏ü‡∏≠‡∏£‡πå‡∏°","‡∏Å‡∏£‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•","fill form","fillform","auto fill","autofill"))
    if explicit_fill: return "fill_form"

    its = intents_from_task_out(out)
    if any(("form" in i) or ("fill_form" in i) or ("accidentreport" in i) for i in its): return "fill_form"
    if any("plan" in i for i in its): return "plan"
    if any("search" in i for i in its) or any("googlesearch" in i for i in its): return "search"

    if low.startswith("‡∏´‡∏≤") or "?" in low: return "search"
    if any(i in ("task","add","check","edit","remove") for i in its): return "task"

    try:
        idxs = task_classify_path(text) or []
        mapping = ["task", "search", "fill_form", "exit_all", "exit_this"]
        if idxs and 0 <= idxs[0] < len(mapping): return mapping[idxs[0]]
    except Exception:
        pass

    return "unknown"

# ---------- fill-form session utils ----------
def _deep_merge_form_keep_existing(base: Any, new: Any) -> Any:
    # deep-merge: ‡∏ñ‡πâ‡∏≤ new ‡πÄ‡∏õ‡πá‡∏ô "" ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°
    if isinstance(base, dict) and isinstance(new, dict):
        out = {}
        keys = set(base.keys()) | set(new.keys())
        for k in keys:
            if k in base and k in new:
                out[k] = _deep_merge_form_keep_existing(base[k], new[k])
            elif k in new:
                out[k] = new[k]
            else:
                out[k] = base[k]
        return out
    if isinstance(new, str):
        return new if new.strip() != "" else (base if isinstance(base, str) else new)
    if isinstance(new, (int, float)) and new is not None:
        return new
    if isinstance(new, list):
        return new
    return new if new is not None else base

def _collect_missing_paths(obj: Any, prefix: List[str] | None = None) -> List[str]:
    prefix = prefix or []
    miss: List[str] = []
    if isinstance(obj, dict):
        for k, v in obj.items():
            miss.extend(_collect_missing_paths(v, prefix + [k]))
        return miss
    if isinstance(obj, str) and obj.strip() == "":
        miss.append(".".join(prefix))
    return miss

def _humanize_field(path: str) -> str:
    labels = {
        "form_1.case_id": "‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏Ñ‡∏™",
        "form_1.participant_id": "‡∏£‡∏´‡∏±‡∏™‡∏ú‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á",

        "form_1.car_info.manufacturer": "‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏£‡∏ñ",
        "form_1.car_info.model": "‡∏£‡∏∏‡πà‡∏ô‡∏£‡∏ñ",
        "form_1.car_info.model_year": "‡∏õ‡∏µ‡∏£‡∏∏‡πà‡∏ô",
        "form_1.car_info.vin": "VIN",
        "form_1.car_info.registration": "‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ",
        "form_1.car_info.type": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ",
        "form_1.car_info.engine": "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå",
        "form_1.car_info.gear": "‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå",
        "form_1.car_info.power": "‡πÅ‡∏£‡∏á‡∏°‡πâ‡∏≤",
        "form_1.car_info.weight": "‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ñ",
        "form_1.car_info.loading_weight": "‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ö‡∏£‡∏£‡∏ó‡∏∏‡∏Å",

        "form_1.driver_info.name": "‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö",
        "form_1.driver_info.license_id": "‡πÉ‡∏ö‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà",
        "form_1.driver_info.dob": "‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö",
        "form_1.driver_info.gender": "‡πÄ‡∏û‡∏®‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö",
        "form_1.driver_info.phone": "‡πÇ‡∏ó‡∏£‡∏®‡∏±‡∏û‡∏ó‡πå",
        "form_1.driver_info.email": "‡∏≠‡∏µ‡πÄ‡∏°‡∏•",
        "form_1.driver_info.nationality": "‡∏™‡∏±‡∏ç‡∏ä‡∏≤‡∏ï‡∏¥",
        "form_1.driver_info.address.subdistrict": "‡∏ï‡∏≥‡∏ö‡∏•/‡πÅ‡∏Ç‡∏ß‡∏á",
        "form_1.driver_info.address.district": "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡πÄ‡∏Ç‡∏ï",
        "form_1.driver_info.address.province": "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
        "form_1.driver_info.address.zipcode": "‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå",

        "form_2.accident_id": "‡∏£‡∏´‡∏±‡∏™‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏",
        "form_2.datetime": "‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏",
        "form_2.location.subdistrict": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏-‡∏ï‡∏≥‡∏ö‡∏•",
        "form_2.location.district": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏-‡∏≠‡∏≥‡πÄ‡∏†‡∏≠",
        "form_2.location.province": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏-‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
        "form_2.location.zipcode": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏-‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå",
        "form_2.weather": "‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®",
        "form_2.road": "‡∏™‡∏†‡∏≤‡∏û‡∏ñ‡∏ô‡∏ô",
        "form_2.environment": "‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°",
        "form_2.cause": "‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏",
        "form_2.detail": "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå",
    }
    return labels.get(path, path)

def _pretty_missing(missing_paths: List[str], limit: int = 6) -> str:
    if not missing_paths:
        return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÅ‡∏•‡πâ‡∏ß"
    labels = [_humanize_field(p) for p in missing_paths[:limit]]
    tail = " ‡∏Ø‡∏•‡∏Ø" if len(missing_paths) > limit else ""
    return ", ".join(labels) + tail

def _ask_prompt_for_field(path: str) -> str:
    prompts = {
        "form_1.case_id": "‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏Ñ‡∏™‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.participant_id": "‡∏£‡∏´‡∏±‡∏™‡∏ú‡∏π‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",

        "form_1.car_info.manufacturer": "‡∏£‡∏ñ‡∏¢‡∏µ‡πà‡∏´‡πâ‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.car_info.model": "‡∏£‡∏∏‡πà‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.car_info.model_year": "‡∏õ‡∏µ‡∏£‡∏∏‡πà‡∏ô (‡∏Ñ.‡∏®.) ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.car_info.vin": "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ï‡∏±‡∏ß‡∏ñ‡∏±‡∏á (VIN) 17 ‡∏ï‡∏±‡∏ß ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.car_info.registration": "‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏£‡∏ñ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.car_info.type": "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö (‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏Å‡πã‡∏á, ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞)?",
        "form_1.car_info.engine": "‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏¢‡∏ô‡∏ï‡πå‡∏£‡∏∏‡πà‡∏ô/‡∏£‡∏´‡∏±‡∏™‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)?",
        "form_1.car_info.gear": "‡πÄ‡∏Å‡∏µ‡∏¢‡∏£‡πå‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö (‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤/‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)?",

        "form_1.driver_info.name": "‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.license_id": "‡πÄ‡∏•‡∏Ç‡πÉ‡∏ö‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.dob": "‡∏ß‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏î‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö (YYYY-MM-DD) ‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.gender": "‡πÄ‡∏û‡∏®‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.phone": "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.email": "‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.address.subdistrict": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö: ‡∏ï‡∏≥‡∏ö‡∏•/‡πÅ‡∏Ç‡∏ß‡∏á ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.address.district": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö: ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡πÄ‡∏Ç‡∏ï ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.address.province": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö: ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_1.driver_info.address.zipcode": "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ú‡∏π‡πâ‡∏Ç‡∏±‡∏ö: ‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏£‡∏±‡∏ö?",

        "form_2.accident_id": "‡∏£‡∏´‡∏±‡∏™‡∏≠‡∏∏‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏´‡∏ï‡∏∏‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.datetime": "‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏´‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö? (‡πÄ‡∏ä‡πà‡∏ô 2025-01-30 14:30)",
        "form_2.location.subdistrict": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ï‡∏≥‡∏ö‡∏•/‡πÅ‡∏Ç‡∏ß‡∏á ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.location.district": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏: ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡πÄ‡∏Ç‡∏ï ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.location.province": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏: ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.location.zipcode": "‡∏à‡∏∏‡∏î‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏: ‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.weather": "‡∏Ç‡∏ì‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏´‡∏ï‡∏∏‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.road": "‡∏™‡∏†‡∏≤‡∏û‡∏ñ‡∏ô‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.environment": "‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.cause": "‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö?",
        "form_2.detail": "‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡πà‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö",
    }
    return prompts.get(path, f"‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• **{_humanize_field(path)}** ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö?")

# ---------- search helpers ----------
def _extract_answer_and_sources(resp: Any) -> tuple[str, List[str]]:
    answer = ""; sources: List[str] = []
    if isinstance(resp, (list, tuple)):
        if len(resp) >= 1 and isinstance(resp[0], str): answer = resp[0]
        if len(resp) >= 2:
            s = resp[1]
            if isinstance(s, str): sources = [s]
            elif isinstance(s, list): sources = [str(x) for x in s if x]
        return answer, sources
    if isinstance(resp, dict):
        if isinstance(resp.get("answer"), str): answer = resp["answer"]
        elif isinstance(resp.get("text"), str):  answer = resp["text"]
        if isinstance(resp.get("source"), str):  sources = [resp["source"]]
        elif isinstance(resp.get("sources"), list): sources = [str(x) for x in resp["sources"] if x]
        return answer, sources
    if isinstance(resp, str): answer = resp
    return answer, sources

def _force_google_with_sources(user_text: str) -> tuple[str, List[str]]:
    try:
        links = search_google(user_text, os.environ.get("SERPAPI_API_KEY"), num_results=3) or []
    except Exception:
        links = []
    summary = ""
    primary = links[0] if links else ""
    try:
        page_text = scrape_text(primary) if primary else ""
        if page_text:
            summary = ask_llm_raw(f"‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô 5 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢:\n{page_text[:4000]}")
    except Exception:
        pass
    if not summary:
        try:
            raw = ask_with_cli_and_fallback(user_text)
        except TypeError:
            raw = ask_with_cli_and_fallback(user_text, os.environ.get("SERPAPI_API_KEY"))
        if isinstance(raw, dict): summary = str(raw.get("answer", "")) or ""
        elif isinstance(raw, str): summary = raw
        else: summary = str(raw)
    return (summary or "‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Google"), links[:3]

# ---------- main endpoint ----------
@app.post("/chat")
def chat(req: ChatIn):
    text = (req.text or "").strip()

    # (A) ‡∏™‡∏±‡πà‡∏á‡∏≠‡∏≠‡∏Å/‡∏™‡∏•‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î (‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏±‡∏ö lock)
    action, target = parse_switch_command(text)
    if action == "exit":
        STATE["feature_lock"] = None
        STATE["fill_form_session"] = None
        msg = feature_badge("unknown") + "‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß"
        return {"text": text, "decorated_input": {"decorated": [
            {"text": text, "response": msg, "intent": ["Exit"]}
        ]}, "message": msg}
    elif action == "switch":
        STATE["feature_lock"] = target
        if target != "fill_form": STATE["fill_form_session"] = None
        # ‡πÑ‡∏õ‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡πÇ‡∏´‡∏°‡∏î‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á

    # (B) ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå intent
    task_out = task_process_input(text)
    intents = intents_from_task_out(task_out)

    # (C) Guard: multi-feature (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ lock) ‚Üí ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô
    if not STATE.get("feature_lock"):
        buckets = detect_multi_feature_request(intents)
        if len(buckets) > 1:
            msg = feature_badge("unknown") + (
                "‡∏Ç‡∏≠‡∏ó‡∏≥‡∏ó‡∏µ‡∏•‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á: "
                + ", ".join(buckets)
                + " ‚Äî ‡πÇ‡∏õ‡∏£‡∏î‡∏û‡∏¥‡∏°‡∏û‡πå '‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤' / '‡πÑ‡∏õ‡∏ó‡∏µ‡πà task' / '‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏ü‡∏≠‡∏£‡πå‡∏°' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏≠‡∏≠‡∏Å'"
            )
            return {
                "text": text,
                "decorated_input": {"decorated": [
                    {"text": text, "response": msg, "intent": ["MultiIntentConflict"], "intents_detected": buckets}
                ]},
                "message": msg
            }

    # (D) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å feature ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ lock
    decided = decide_feature(text, task_out)

    # (E) FEATURE LOCK (‡πÄ‡∏Ç‡πâ‡∏°)
    lock = STATE.get("feature_lock")
    if lock:
        feature = lock
    else:
        feature = decided
        if feature in ("task", "search", "plan", "fill_form"):
            STATE["feature_lock"] = feature

    # helper: ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏° badge ‡πÇ‡∏´‡∏°‡∏î
    def std_response(feature_name: str, message: str, decorated: Optional[List[Dict[str, Any]]] = None):
        return {
            "text": text,
            "decorated_input": {"decorated": decorated or []},
            "message": feature_badge(feature_name) + message
        }

    # ===== TASK (lock ‡πÄ‡∏Ç‡πâ‡∏°) =====
    if feature == "task":
        di = task_out.get("decorated_input") or {}
        decorated = di.get("decorated", []) if isinstance(di, dict) else []
        msg = task_out.get("message", "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß") + " (‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)"
        return std_response("task", msg, decorated)

    # ===== SEARCH (lock ‡πÄ‡∏Ç‡πâ‡∏°) =====
    if feature == "search":
        add_log("search", "user", text)
        prompt = build_search_prompt(text)
        try:
            raw = ask_with_cli_and_fallback(prompt)
        except TypeError:
            raw = ask_with_cli_and_fallback(prompt, os.environ.get("SERPAPI_API_KEY"))
        answer, sources = _extract_answer_and_sources(raw)
        unknown_flags = ("‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ","‡πÑ‡∏°‡πà‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à","‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•","‡πÑ‡∏°‡πà‡∏û‡∏ö","‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢","‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
        if (not answer) or any(f in str(answer) for f in unknown_flags):
            answer, sources = _force_google_with_sources(text)
            intent = ["Search","GoogleSearch"]
        else:
            intent = ["Search"]
        add_log("search", "assistant", answer)
        resp = answer + "\n\n(‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)"
        return std_response("search", resp, [
            {"text": text, "response": answer, "sources": sources, "intent": intent}
        ])

    # ===== PLAN (option) =====
    if feature == "plan":
        plan_text = ask_llm_raw(text)
        resp = (plan_text or "‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÅ‡∏•‡πâ‡∏ß") + "\n\n(‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)"
        return std_response("plan", resp, [
            {"text": text, "response": plan_text, "intent": ["Plan"]}
        ])

    # ===== FILL_FORM (interactive + lock ‡πÄ‡∏Ç‡πâ‡∏°) =====
    if feature == "fill_form":
        af = run_autofill(text)  # ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á: {"form": {...}, "missing_fields": [...], "filled_fields": [...], "error": "", "confidence": 0.x}
        new_form = af.get("form", {})
        err = af.get("error", "")

        sess = STATE.get("fill_form_session") or {}
        cur_form = sess.get("form") or {}
        merged = _deep_merge_form_keep_existing(cur_form, new_form)

        missing = _collect_missing_paths(merged)
        filled: List[str] = []

        STATE["fill_form_session"] = {"form": merged, "missing": missing, "filled": filled}

        if err:
            msg = f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ï‡∏¥‡∏°‡∏ü‡∏≠‡∏£‡πå‡∏°: {err}\n(‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)"
        else:
            if missing:
                nice_list = _pretty_missing(missing)
                ask = _ask_prompt_for_field(missing[0])
                msg = (
                    "‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏≤‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß üëç\n"
                    f"‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡∏Ç‡∏≤‡∏î: {nice_list}\n"
                    f"{ask}\n"
                    "(‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠)"
                )
            else:
                msg = "‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏ä‡πà‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß!\n(‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)"

        decorated = [{
            "text": text,
            "form": merged,
            "error": err,
            "confidence": af.get("confidence", 0.0),
            "intent": ["FillForm"],
            "missing_fields": missing,
            "filled_fields": filled,
            "notes": af.get("notes", "")
        }]
        return std_response("fill_form", msg, decorated)

    # ===== ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ lock ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏î =====
    if STATE.get("feature_lock"):
        msg = f"‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î '{STATE['feature_lock']}' ‚Äî ‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠ '‡πÑ‡∏õ‡∏ó‡∏µ‡πà <search/task/form>' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏•‡∏±‡∏ö"
        return std_response(STATE["feature_lock"], msg, [{"text": text, "response": msg, "intent": ["Notice"]}])

    # ===== default: search + lock =====
    add_log("search", "user", text)
    answer, sources = _force_google_with_sources(text)
    add_log("search", "assistant", answer)
    if not STATE.get("feature_lock"): STATE["feature_lock"] = "search"
    resp = answer + "\n\n(‡∏û‡∏¥‡∏°‡∏û‡πå '‡∏≠‡∏≠‡∏Å' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∑‡πà‡∏ô)"
    return std_response("search", resp, [
        {"text": text, "response": answer, "sources": sources, "intent": ["Search"]}
    ])
